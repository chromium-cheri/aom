{
  "comments": [
    {
      "unresolved": true,
      "key": {
        "uuid": "8d825bbc_3813a334",
        "filename": "/COMMIT_MSG",
        "patchSetId": 3
      },
      "lineNbr": 16,
      "author": {
        "id": 9545
      },
      "writtenOn": "2023-12-06T21:56:58Z",
      "side": 1,
      "message": "I inspected all the `sync_write()` functions in libaom.\n\nPlease check the `sync_write()` function in av1/decoder/decodeframe.c. It may have the same issue.",
      "revId": "305a8f9b51c24fa4b198ca5faed239d9f2268724",
      "serverId": "e5514cf8-2d6e-3e29-adb4-24cd6dde4bf0"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "abfdebac_8bdd5879",
        "filename": "/COMMIT_MSG",
        "patchSetId": 3
      },
      "lineNbr": 16,
      "author": {
        "id": 25857
      },
      "writtenOn": "2023-12-07T10:22:31Z",
      "side": 1,
      "message": "Thank you for the review. As mentioned in the review message, currently the `sync_write()` function in av1/decoder/decodeframe.c doesn\u0027t need this fix because of the max thread constraint (`AOM_MAX_THREADS_PER_TILE`). Please let us know your suggestion.",
      "parentUuid": "8d825bbc_3813a334",
      "revId": "305a8f9b51c24fa4b198ca5faed239d9f2268724",
      "serverId": "e5514cf8-2d6e-3e29-adb4-24cd6dde4bf0"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "f1f6a5ee_ac204a91",
        "filename": "/COMMIT_MSG",
        "patchSetId": 3
      },
      "lineNbr": 16,
      "author": {
        "id": 9545
      },
      "writtenOn": "2023-12-07T16:10:35Z",
      "side": 1,
      "message": "I am not familiar with the multithreading code in av1/decoder/decodeframe.c, so this comment is based on a quick analysis.\n\nWhen I compare `decode_tile_sb_row()` in decodeframe.c with `encode_sb_row()` in encodeframe.c, I see an important difference in whether `row_mt_exit` causes the function to exit the for loop. I am wondering if we should change `decode_tile_sb_row()` to also exit the for loop when `row_mt_exit` is true.\n\nAs for whether the `sync_write()` function in decodeframe.c needs this fix, I am sorry that I don\u0027t know. The question is whether one thread will deadlock in this for loop when the other thread has encountered an error and exited:\n\n```\n  for (int mi_col \u003d tile_info-\u003emi_col_start; mi_col \u003c tile_info-\u003emi_col_end;\n       mi_col +\u003d cm-\u003eseq_params-\u003emib_size, sb_col_in_tile++) {\n    ...\n\n    sync_read(\u0026tile_data-\u003edec_row_mt_sync, sb_row_in_tile, sb_col_in_tile);\n\n#if CONFIG_MULTITHREAD\n    pthread_mutex_lock(pbi-\u003erow_mt_mutex_);\n#endif\n    row_mt_exit \u003d pbi-\u003eframe_row_mt_info.row_mt_exit;\n#if CONFIG_MULTITHREAD\n    pthread_mutex_unlock(pbi-\u003erow_mt_mutex_);\n#endif\n\n    if (!row_mt_exit) {\n      // Decoding of the super-block\n      decode_partition(pbi, td, mi_row, mi_col, td-\u003ebit_reader,\n                       cm-\u003eseq_params-\u003esb_size, 0x2);\n    }\n\n    sync_write(\u0026tile_data-\u003edec_row_mt_sync, sb_row_in_tile, sb_col_in_tile,\n               sb_cols_in_tile);\n  }\n```\n\nIf this `sync_write()` call decreases the col number from the  max col number (written by the failed thread) to `sb_col_in_tile`, will  this thread deadlock in the next `sync_read()` call when it loops around?\n\nIf this deadlock cannot happen when AOM_MAX_THREADS_PER_TILE is 2 but can happen when AOM_MAX_THREADS_PER_TILE is \u003e 2, then I suggest one of the following:\n- Add a comment at the definition of the AOM_MAX_THREADS_PER_TILE macro to remind people that they need to add the fix if they increase AOM_MAX_THREADS_PER_TILE to 3 or more.\n- Just add the fix.\n\nWhile researching this issue, I found another potential issue:\n\n```\n#if CONFIG_MULTITHREAD\n    pthread_mutex_lock(pbi-\u003erow_mt_mutex_);\n#endif\n    frame_row_mt_info-\u003erow_mt_exit \u003d 1;\n\n    // If any SB row (erroneous row) processed by a thread encounters an\n    // internal error, there is a need to indicate other threads that decoding\n    // of the erroneous row is complete. This ensures that other threads which\n    // wait upon the completion of SB\u0027s present in erroneous row are not waiting\n    // indefinitely.\n    signal_decoding_done_for_erroneous_row(pbi, \u0026thread_data-\u003etd-\u003edcb.xd);\n\n#if CONFIG_MULTITHREAD\n    pthread_cond_broadcast(pbi-\u003erow_mt_cond_);\n    pthread_mutex_unlock(pbi-\u003erow_mt_mutex_);\n#endif\n```\n\nSince the `signal_decoding_done_for_erroneous_row()` call also locks a mutex internally, the code here needs to lock two mutexes. If it is not necessary to call `signal_decoding_done_for_erroneous_row()` while holding `pbi-\u003erow_mt_mutex_`, I suggest we call `signal_decoding_done_for_erroneous_row()` after unlocking `pbi-\u003erow_mt_mutex_`.",
      "parentUuid": "abfdebac_8bdd5879",
      "revId": "305a8f9b51c24fa4b198ca5faed239d9f2268724",
      "serverId": "e5514cf8-2d6e-3e29-adb4-24cd6dde4bf0"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "d097fe7b_58a48362",
        "filename": "/COMMIT_MSG",
        "patchSetId": 3
      },
      "lineNbr": 16,
      "author": {
        "id": 25857
      },
      "writtenOn": "2023-12-12T16:19:59Z",
      "side": 1,
      "message": "After studying the decoder’s design of error handling we see that it is different from that of the encoder, and this issue is not possible even when the constraint of 2 threads is removed. This is because an erroneous thread in the decoder will set `row_mt_exit` to 1 and invoke `signal_decoding_done_for_erroneous_row()` which sets `num_finished_cols[r]` to the maximum column number where `r` is the erroneous row (not for all the rows in the frame/tile). The non erroneous threads which have already picked jobs (`decode_tile_sb_row()`) will skip `decode_partition()` based on the `row_mt_exit` flag but will invoke `sync_write()` for all SB columns to avoid dependent threads from waiting indefinitely. The non-erroneous threads would later exit while picking the next job (please see `get_next_job_info()`). Hence the threads do not exit immediately in `decode_tile_sb_row()` after checking the `row_mt_exit` flag.\n\nWe see 2 possible approaches if we want the non-erroneous threads (which are in progress) to exit immediately:\nApproach 1: If `row_mt_exit` is true, invoke `sync_write()` for the current row with maximum column number and exit\nApproach 2: Implement a design similar to encoder which would involve the below 3 changes: \n           a. Modify `signal_decoding_done_for_erroneous_row()` to update decoding done for all rows\n           b. Modify `sync_write()` similar to current CL\n           c. Exit early after checking `row_mt_exit` flag      \n \nApproach 1 would adhere to the current error handling design of the decoder, whereas Approach 2 may require more changes to current error handling design. Please let us know your opinion.\n\n\n\u003e Since the signal_decoding_done_for_erroneous_row() call also locks a mutex internally, the code here needs to lock two mutexes. If it is not necessary to call signal_decoding_done_for_erroneous_row() while holding pbi-\u003erow_mt_mutex_, I suggest we call signal_decoding_done_for_erroneous_row() after unlocking pbi-\u003erow_mt_mutex_.\n\nAcknowledge. As per our code study `signal_decoding_done_for_erroneous_row()` doesn\u0027t need to be called under `pbi-\u003erow_mt_mutex_` lock. We shall submit a CL addressing this.",
      "parentUuid": "f1f6a5ee_ac204a91",
      "revId": "305a8f9b51c24fa4b198ca5faed239d9f2268724",
      "serverId": "e5514cf8-2d6e-3e29-adb4-24cd6dde4bf0"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "a8940c8b_399c27c9",
        "filename": "/COMMIT_MSG",
        "patchSetId": 3
      },
      "lineNbr": 16,
      "author": {
        "id": 9545
      },
      "writtenOn": "2023-12-14T01:45:30Z",
      "side": 1,
      "message": "Thank you for the explanation. I am not familiar with the decoder multithreading code, and I am sorry that I didn\u0027t study the code when I read your explanation. So I don\u0027t fully understand the explanation.\n\nBut I think the non-erroneous threads don\u0027t need to exit immediately, because decoding is fast. Is my partial answer sufficient?\n\nPlease let me know if you\u0027d like me to study the code and fully understand your explanation. Thanks.",
      "parentUuid": "d097fe7b_58a48362",
      "revId": "305a8f9b51c24fa4b198ca5faed239d9f2268724",
      "serverId": "e5514cf8-2d6e-3e29-adb4-24cd6dde4bf0"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "587b3ffd_cfdebc61",
        "filename": "/COMMIT_MSG",
        "patchSetId": 3
      },
      "lineNbr": 16,
      "author": {
        "id": 25857
      },
      "writtenOn": "2023-12-14T17:04:30Z",
      "side": 1,
      "message": "As this bug is not present in the decoder error handling framework and as the immediate exit of non-erroneous threads might not be required as suggested, we can leave the decoder error handling code as is. Thank you!",
      "parentUuid": "a8940c8b_399c27c9",
      "revId": "305a8f9b51c24fa4b198ca5faed239d9f2268724",
      "serverId": "e5514cf8-2d6e-3e29-adb4-24cd6dde4bf0"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "c5bcb4f4_c8a09db1",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 3
      },
      "lineNbr": 0,
      "author": {
        "id": 25857
      },
      "writtenOn": "2023-12-05T17:27:46Z",
      "side": 1,
      "message": "In the parent commit, for a few MT modules, when a thread encounters an error it will invoke the respective `sync_write()` function to set the `num_finished_cols[r]` of every row to a maximum column number in order to avoid dependent workers from waiting indefinitely. This maximum column number can be overwritten by a non-erroneous thread with a lower column number causing the dependent worker to wait indefinitely. This CL resolves this issue in loop filter, loop restoration and TPL MT modules, by modifying the respective `sync_write()` functions such that they will never decrease the `num_finished_cols[r]`. A similar fix is already done for other encoder modules in [CL](https://aomedia-review.googlesource.com/c/aom/+/180642).\n\nThis issue is reproducible only if a minimum of three threads are working in parallel on a tile. A similar fix is currently not required for the `sync_write()` function of decoder, as the decoder has a constraint of maximum 2 threads per tile (`AOM_MAX_THREADS_PER_TILE`). Please let us know if we should do this fix for the decoder as well to avoid  deadlock issues in the future if this constraint is removed.\n\nThis change is bit-exact and has been verified using bitstream-match tests for a combination of various configuration values for --threads, --tile-rows, --tile-columns, --cpu-used, --end-usage, --row-mt, --fp-mt, etc. Validated all unit-tests with sanitizers (address and thread) and valgrind.",
      "revId": "305a8f9b51c24fa4b198ca5faed239d9f2268724",
      "serverId": "e5514cf8-2d6e-3e29-adb4-24cd6dde4bf0"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "57eaeb69_cd6e4fe8",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 3
      },
      "lineNbr": 0,
      "author": {
        "id": 9545
      },
      "writtenOn": "2023-12-07T16:45:47Z",
      "side": 1,
      "message": "\u003e This issue is reproducible only if a minimum of three threads are working in parallel on a tile. A similar fix is currently not required for the `sync_write()` function of decoder, as the decoder has a constraint of maximum 2 threads per tile (`AOM_MAX_THREADS_PER_TILE`). Please let us know if we should do this fix for the decoder as well to avoid  deadlock issues in the future if this constraint is removed.\n\nHi Mudassir,\n\nI am sorry I started reviewing this CL without reading this review message. Please consider this when you read my earlier comments.\n\nAlso, if it\u0027s easy to explain why this bug requires at least three threads, I\u0027d love to understand it. Don\u0027t worry about it if the explanation is complicated.",
      "parentUuid": "c5bcb4f4_c8a09db1",
      "revId": "305a8f9b51c24fa4b198ca5faed239d9f2268724",
      "serverId": "e5514cf8-2d6e-3e29-adb4-24cd6dde4bf0"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "324c6c2c_55d0e7a0",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 3
      },
      "lineNbr": 0,
      "author": {
        "id": 25857
      },
      "writtenOn": "2023-12-12T16:19:59Z",
      "side": 1,
      "message": "Hi Wan-Teh,\nThank you for reviewing and merging the CL.\n\nOn further study of the error handling framework on the decoder side, we see that this deadlock scenario is not possible even if the number of threads \u003e\u003d 3. However the deadlock is possible in encoder only if number of threads \u003e\u003d 3 as explained below.\n\nConsider that threads t0, t1, and t2 are encoding rows r0, r1 and r2 respectively. When t0 encounters an error it will set `num_finished_cols[r]` to the maximum column number for all the rows in the frame. Thread t1 which just finishes encoding a block in row r1 can overwrite `num_finished_cols[r1]` with a smaller column number. This overwrite can cause its dependent thread t2 to wait indefinitely in `sync_read()` but will not affect t1 from exiting early (as t1 is only dependent on `num_finished_cols[r0]`). \n\nWe have described our findings on decoder framework as response to your other comments.",
      "parentUuid": "57eaeb69_cd6e4fe8",
      "revId": "305a8f9b51c24fa4b198ca5faed239d9f2268724",
      "serverId": "e5514cf8-2d6e-3e29-adb4-24cd6dde4bf0"
    }
  ],
  "submitRequirementResults": [
    {
      "submitRequirement": {
        "name": "Code-Review",
        "description": {
          "value": "At least one maximum vote for label \u0027Code-Review\u0027 is required"
        },
        "applicabilityExpression": {},
        "submittabilityExpression": {
          "expressionString": "label:Code-Review\u003dMAX,user\u003dnon_uploader AND -label:Code-Review\u003dMIN"
        },
        "overrideExpression": {
          "value": {
            "expressionString": "label:Bot-Commit\u003d+1 AND -label:Code-Review\u003dMIN"
          }
        },
        "allowOverrideInChildProjects": true
      },
      "applicabilityExpressionResult": {},
      "submittabilityExpressionResult": {
        "value": {"expression":{"expressionString":"label:Code-Review=MAX,user=non_uploader AND -label:Code-Review=MIN"},"status":"PASS","errorMessage":{"value":null},"passingAtoms":["label:Code-Review=MAX,user=non_uploader"],"failingAtoms":["label:Code-Review=MIN"]}
      },
      "overrideExpressionResult": {
        "value": {"expression":{"expressionString":"label:Bot-Commit=+1 AND -label:Code-Review=MIN"},"status":"FAIL","errorMessage":{"value":null},"passingAtoms":[],"failingAtoms":["label:Bot-Commit=+1","label:Code-Review=MIN"]}
      },
      "patchSetCommitId": "305a8f9b51c24fa4b198ca5faed239d9f2268724",
      "legacy": {
        "value": false
      },
      "forced": {},
      "hidden": {}
    },
    {
      "submitRequirement": {
        "name": "Review-Enforcement",
        "description": {
          "value": "Two Google employees must approve the change. Uploading the change or voting positively on Code-Review count as approval."
        },
        "applicabilityExpression": {
          "value": {
            "expressionString": "is:review-enforced_gerrit"
          }
        },
        "submittabilityExpression": {
          "expressionString": "is:review-enforcement-satisfied_gerrit"
        },
        "overrideExpression": {},
        "allowOverrideInChildProjects": false
      },
      "applicabilityExpressionResult": {
        "value": {"expression":{"expressionString":"is:review-enforced_gerrit"},"status":"PASS","errorMessage":{"value":null},"passingAtoms":["is:review-enforced_gerrit"],"failingAtoms":[]}
      },
      "submittabilityExpressionResult": {
        "value": {"expression":{"expressionString":"is:review-enforced_gerrit"},"status":"PASS","errorMessage":{"value":null},"passingAtoms":[],"failingAtoms":["is:review-enforcement-satisfied_gerrit"]}
      },
      "overrideExpressionResult": {},
      "patchSetCommitId": "305a8f9b51c24fa4b198ca5faed239d9f2268724",
      "legacy": {
        "value": false
      },
      "forced": {},
      "hidden": {
        "value": true
      }
    },
    {
      "submitRequirement": {
        "name": "Verified",
        "description": {
          "value": "CI or human verified the change"
        },
        "applicabilityExpression": {},
        "submittabilityExpression": {
          "expressionString": "label:Verified\u003dMAX AND -label:Verified\u003dMIN"
        },
        "overrideExpression": {
          "value": {
            "expressionString": "label:Bot-Commit\u003d+1"
          }
        },
        "allowOverrideInChildProjects": true
      },
      "applicabilityExpressionResult": {},
      "submittabilityExpressionResult": {
        "value": {"expression":{"expressionString":"label:Verified=MAX AND -label:Verified=MIN"},"status":"PASS","errorMessage":{"value":null},"passingAtoms":["label:Verified=MAX"],"failingAtoms":["label:Verified=MIN"]}
      },
      "overrideExpressionResult": {
        "value": {"expression":{"expressionString":"label:Bot-Commit=+1"},"status":"FAIL","errorMessage":{"value":null},"passingAtoms":[],"failingAtoms":["label:Bot-Commit=+1"]}
      },
      "patchSetCommitId": "305a8f9b51c24fa4b198ca5faed239d9f2268724",
      "legacy": {
        "value": false
      },
      "forced": {},
      "hidden": {}
    }
  ]
}