{
  "comments": [
    {
      "unresolved": false,
      "key": {
        "uuid": "65088935_b1bdd586",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 5
      },
      "lineNbr": 0,
      "author": {
        "id": 5185
      },
      "writtenOn": "2021-04-29T23:39:29Z",
      "side": 1,
      "message": "Hi Chi Yo, I remember you looked at this before. What was the conclusion?",
      "revId": "faf8e81969261cd227bd530dd138419857bbc126",
      "serverId": "e5514cf8-2d6e-3e29-adb4-24cd6dde4bf0"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "dc2db6d1_44dc06b1",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 5
      },
      "lineNbr": 0,
      "author": {
        "id": 9823
      },
      "writtenOn": "2021-04-29T23:51:06Z",
      "side": 1,
      "message": "My concern is that the user might first encode without delta-q, and then re-encode with delta-q using the same first pass stats. This would give the user a suboptimal result.\n\nWe could work around this by detecting whether the first pass wavelet energy is valid by checking if it\u0027s all zero. If it is, then it\u0027s likely to be invalid, and we can skip the ml-model and prints a warning saying that the firstpass stats is invalid.",
      "parentUuid": "65088935_b1bdd586",
      "revId": "faf8e81969261cd227bd530dd138419857bbc126",
      "serverId": "e5514cf8-2d6e-3e29-adb4-24cd6dde4bf0"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "ada30a5c_556e0041",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 5
      },
      "lineNbr": 0,
      "author": {
        "id": 5185
      },
      "writtenOn": "2021-04-30T00:11:15Z",
      "side": 1,
      "message": "From Urvang\u0027s CL:\nhttps://aomedia-review.googlesource.com/c/aom/+/88422\n\nThis ml model helped UGC set coding performance. Maybe it can be extended to vbr mode as he mentioned in the CL.",
      "parentUuid": "dc2db6d1_44dc06b1",
      "revId": "faf8e81969261cd227bd530dd138419857bbc126",
      "serverId": "e5514cf8-2d6e-3e29-adb4-24cd6dde4bf0"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "899db4e3_830c3809",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 5
      },
      "lineNbr": 0,
      "author": {
        "id": 8893
      },
      "writtenOn": "2021-05-05T09:10:40Z",
      "side": 1,
      "message": "Hi Yunqing, \n\nWe tried disabling the ML model in AOM_Q mode. Following are the results for ugc360p with no change in coding performance over BORG test suite.\n\n cpu-used    Instruction             BD-Rate Loss(%)\n          Count Reduction(%)   avg.psnr  ovr.psnr  ssim\n  5              -1.513        -0.1607   -0.0992   -0.6795\n  6              -1.060        -0.0402    0.0116   -0.1339\n  \n\nFrom the results above, we see that disabling the ML model is resulting in slight BD-Rate gain for speed 5, 6. \n\nWe also tried enabling the ML model for AOM_VBR mode. The results for ugc360p are as follows with no change in coding performance over BORG test suite.\n\n cpu-used    Instruction             BD-Rate Loss(%)\n          Count Reduction(%)   avg.psnr  ovr.psnr  ssim\n  5              1.100         0.2763     0.5952   1.2735\n  6              0.992         0.2901     0.4793   1.0643\n  \n\nThe results do not meet the expected BD-Rate vs speed trade-off. \n\nThus we feel that it is better to disable the ML model for speed 5, 6 (by introducing a speed feature). Thereby, for speed 5, 6 we can remove those calculations in first pass which are required only for the ML model. This would result in ~2% instruction count reduction  (this patch + avoiding motion search w.r.t third reference in first pass) for both speed 5, 6 with no change in coding performance. \n\nPlease let us know your opinion.",
      "parentUuid": "ada30a5c_556e0041",
      "revId": "faf8e81969261cd227bd530dd138419857bbc126",
      "serverId": "e5514cf8-2d6e-3e29-adb4-24cd6dde4bf0"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "92ba0efc_6a60e2d0",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 5
      },
      "lineNbr": 0,
      "author": {
        "id": 5185
      },
      "writtenOn": "2021-05-05T18:49:08Z",
      "side": 1,
      "message": "Thanks for the further testing. What does this mean: \"with no change in coding performance over BORG test suite\"? There is coding performance change, right?\n\nDisabling the ML model in AOM_Q mode gives slight coding gain on ugc360p set - this is quite different from original CL\u0027s result. Is it because you test speed 5 instead of a low speed (speed 1 or 2)? Or something else is different? More testing can be helpful for us to reach a conclusion.\n\nA general practice for 2-pass encoding is to use a high speed for first pass and a low speed for second pass. For example, 1st pass uses speed 4 and 2nd pass uses speed 2. In this case, adding speed feature in 1st pass can be tricky. We might still need a good solution to handle it. What do you think?",
      "parentUuid": "899db4e3_830c3809",
      "revId": "faf8e81969261cd227bd530dd138419857bbc126",
      "serverId": "e5514cf8-2d6e-3e29-adb4-24cd6dde4bf0"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "91839fbe_b6f141fd",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 5
      },
      "lineNbr": 0,
      "author": {
        "id": 8893
      },
      "writtenOn": "2021-05-10T16:25:16Z",
      "side": 1,
      "message": "Hi Yunqing,\n\nWe performed some more testing and following are the results of enabling the ML model (which predicts the gop structure) in AOM_Q mode for ugc360p set. \n\nCommit id : 38b7e84 (June 2019) with lag-in-frames\u003d19 (lag-in-frames\u003d35 was not supported then)\n\n cpu-used    Instruction count            BD-Rate Loss (%)\n                Reduction (%)     avg.psnr    ovr.psnr    ssim                                     \n    1              1.866          -0.5148    -0.6187    -0.2562\n    2              1.788          -0.4928    -0.6069    -0.2421\n    3              1.295          -0.4486    -0.5654    -0.195\n    4              1.085          -0.4419    -0.5576    -0.1938\n    5              0.815          -0.4606    -0.5794    -0.1957\n    6              0.672          -0.4941    -0.6113    -0.2011\n                    \nCommit id : 2971930 (April 2021) with lag-in-frames\u003d19\n\n cpu-used    Instruction count          BD-Rate Loss (%)\n                Reduction (%)     avg.psnr    ovr.psnr    ssim                            \n    1             -0.207          -0.0897     -0.0940     -0.0074\n    2              0.990          -0.1704     -0.1582     -0.0430\n    3              1.411          -0.1788     -0.1919     -0.0513\n    4              1.152          -0.2126     -0.2001     -0.0444\n    5              1.154          -0.0498     -0.0997      0.0704\n    6              1.090          -0.0707     -0.1128      0.0429\n                    \nCommit id : 2971930 (April 2021) with lag-in-frames\u003d35\n\n cpu-used    Instruction count         BD-Rate Loss (%)\n                Reduction (%)     avg.psnr    ovr.psnr    ssim                      \n    1             -0.302          -0.0031      0.1118     0.1294\n    2              1.287          -0.0412      0.0860     0.1145\n    3              1.956          -0.0435     -0.0953     0.0662\n    4              1.710          -0.1490     -0.1941    -0.0059\n    5              1.316           0.1904      0.1366     0.9999\n    6              0.942           0.0523      0.0042     0.1470\n\n \n\nFrom the data above we see that the gains by enabling the ML model has reduced in the recent versions and are seen to be further lesser with lag-in-frames\u003d35.",
      "parentUuid": "92ba0efc_6a60e2d0",
      "revId": "faf8e81969261cd227bd530dd138419857bbc126",
      "serverId": "e5514cf8-2d6e-3e29-adb4-24cd6dde4bf0"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "2df56fa0_ae56b04c",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 5
      },
      "lineNbr": 0,
      "author": {
        "id": 5185
      },
      "writtenOn": "2021-05-10T16:48:09Z",
      "side": 1,
      "message": "Hi Urvang,\n\nPlease take a look at Deepa\u0027s test results, which showed the gains by enabling the ML model was reduced. Any suggestions for getting back the coding gain for ugc set?",
      "revId": "faf8e81969261cd227bd530dd138419857bbc126",
      "serverId": "e5514cf8-2d6e-3e29-adb4-24cd6dde4bf0"
    }
  ]
}