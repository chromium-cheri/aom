{
  "comments": [
    {
      "key": {
        "uuid": "24a0d7f8_7aedc354",
        "filename": "aom/src/aom_encoder.c",
        "patchSetId": 3
      },
      "lineNbr": 191,
      "author": {
        "id": 10034
      },
      "writtenOn": "2020-01-10T18:08:38Z",
      "side": 1,
      "message": "Please slightly expand this comment -- mention that TF-lite allows for certain kinds of FPE as part of computation, so this has to be disabled in order to work with it.",
      "range": {
        "startLine": 191,
        "startChar": 0,
        "endLine": 191,
        "endChar": 55
      },
      "revId": "9a086c2f97a018a4a724b89b8173dba665b0ec07",
      "serverId": "e5514cf8-2d6e-3e29-adb4-24cd6dde4bf0",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "2dbbcc36_57cd4173",
        "filename": "aom/src/aom_encoder.c",
        "patchSetId": 3
      },
      "lineNbr": 191,
      "author": {
        "id": 5290
      },
      "writtenOn": "2020-01-10T18:29:54Z",
      "side": 1,
      "message": "Done",
      "parentUuid": "24a0d7f8_7aedc354",
      "range": {
        "startLine": 191,
        "startChar": 0,
        "endLine": 191,
        "endChar": 55
      },
      "revId": "9a086c2f97a018a4a724b89b8173dba665b0ec07",
      "serverId": "e5514cf8-2d6e-3e29-adb4-24cd6dde4bf0",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "49fd64db_e0c74a81",
        "filename": "av1/common/cnn_tflite.cc",
        "patchSetId": 3
      },
      "lineNbr": 22,
      "author": {
        "id": 10034
      },
      "writtenOn": "2020-01-10T18:08:38Z",
      "side": 1,
      "message": "Would caching the interpreter with a static variable help with speed? Otherwise (I think) it has to rebuild the model one each invocation.",
      "range": {
        "startLine": 22,
        "startChar": 1,
        "endLine": 22,
        "endChar": 45
      },
      "revId": "9a086c2f97a018a4a724b89b8173dba665b0ec07",
      "serverId": "e5514cf8-2d6e-3e29-adb4-24cd6dde4bf0",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "db909780_aec6d534",
        "filename": "av1/common/cnn_tflite.cc",
        "patchSetId": 3
      },
      "lineNbr": 22,
      "author": {
        "id": 5290
      },
      "writtenOn": "2020-01-10T18:29:54Z",
      "side": 1,
      "message": "Good suggestion, that\u0027s worth a try indeed.\nThis will have to handle the case when model is switched based on qindex though.\nSo, let me put a TODO for now.\nI plan to add model switching first, and after that will interpreter caching.",
      "parentUuid": "49fd64db_e0c74a81",
      "range": {
        "startLine": 22,
        "startChar": 1,
        "endLine": 22,
        "endChar": 45
      },
      "revId": "9a086c2f97a018a4a724b89b8173dba665b0ec07",
      "serverId": "e5514cf8-2d6e-3e29-adb4-24cd6dde4bf0",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "a9ab4a2b_759b2fa2",
        "filename": "av1/common/cnn_tflite.cc",
        "patchSetId": 3
      },
      "lineNbr": 90,
      "author": {
        "id": 5290
      },
      "writtenOn": "2020-01-10T18:29:54Z",
      "side": 1,
      "message": "Note: I removed this TODO, because using such a model drops performance slightly -- possibly due to clipping being performed at lower precision (when value is in range 0 to 1), instead of at higher precision at the very end (when value is in range 0 to 255).",
      "revId": "9a086c2f97a018a4a724b89b8173dba665b0ec07",
      "serverId": "e5514cf8-2d6e-3e29-adb4-24cd6dde4bf0",
      "unresolved": false
    }
  ]
}